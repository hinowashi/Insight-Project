{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insight Project --Birding Big Year--\n",
    "\n",
    "In this project I intend to determine a way to see all the birds one can see on a single state, for a given time window.  For all those birdirers that want to get to the top 100 of their state on ebrid, this will be the perfect tool. The user will input the state, home address (or lat,lon), time window and birds that already have been seen*. This last one (*) is an optional thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import struct\n",
    "import pickle\n",
    "import googlemaps\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import SetCover\n",
    "import DBScaner\n",
    "import Definition\n",
    "\n",
    "def save_fig(name):\n",
    "    fig.savefig(name,dpi=80,bbox_inches='tight', pad_inches=0.02, format = 'png')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ebird Data\n",
    "\n",
    "I will start with a singe state. Since the ebird API limits the type of request I can make, I have a downloaded the cvs file.  I'm using the last two full years of data but in reality the alorithm should be train with more data and just tested on the last year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(DBScaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = Definition.DBNAME\n",
    "username = Definition.USERNAME\n",
    "pswd = Definition.PSWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nSELECT * FROM wisconsin_birds WHERE year = 2018;\n': relation \"wisconsin_birds\" does not exist\nLINE 2: SELECT * FROM wisconsin_birds WHERE year = 2018;\n                      ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedTable\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/insight/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1586\u001b[0;31m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1587\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUndefinedTable\u001b[0m: relation \"wisconsin_birds\" does not exist\nLINE 2: SELECT * FROM wisconsin_birds WHERE year = 2018;\n                      ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-361b74a04078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mSELECT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFROM\u001b[0m \u001b[0mwisconsin_birds\u001b[0m \u001b[0mWHERE\u001b[0m \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2018\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \"\"\"\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdfTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_query\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/insight/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \"\"\"\n\u001b[1;32m    325\u001b[0m     \u001b[0mpandas_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/insight/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/insight/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Execution failed on sql '{args[0]}': {exc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\nSELECT * FROM wisconsin_birds WHERE year = 2018;\n': relation \"wisconsin_birds\" does not exist\nLINE 2: SELECT * FROM wisconsin_birds WHERE year = 2018;\n                      ^\n"
     ]
    }
   ],
   "source": [
    "## Now try the same queries, but in python!\n",
    "\n",
    "# connect:\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username, host='localhost', password=pswd)\n",
    "\n",
    "# query:\n",
    "sql_query = \"\"\"\n",
    "SELECT * FROM data_lower WHERE year = 2018;\n",
    "\"\"\"\n",
    "dfTrain = pd.read_sql_query(sql_query,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sampling_event_identifier</th>\n",
       "      <th>common name</th>\n",
       "      <th>locality</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>observation_date</th>\n",
       "      <th>all_species_reported</th>\n",
       "      <th>year_week</th>\n",
       "      <th>year_day</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>S46395227</td>\n",
       "      <td>Red-eyed Vireo</td>\n",
       "      <td>Riverside Park (Urban Ecology Center)</td>\n",
       "      <td>43.067967</td>\n",
       "      <td>-87.892686</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>S47723667</td>\n",
       "      <td>Pine Siskin</td>\n",
       "      <td>Schlitz Audubon Nature Center</td>\n",
       "      <td>43.175688</td>\n",
       "      <td>-87.890421</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>S44649385</td>\n",
       "      <td>Mallard</td>\n",
       "      <td>Manitowoc Lakefront</td>\n",
       "      <td>44.092794</td>\n",
       "      <td>-87.650170</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>106</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>S43252514</td>\n",
       "      <td>Mallard</td>\n",
       "      <td>UW Lakeshore Nature Preserve--Willow Creek Woo...</td>\n",
       "      <td>43.077869</td>\n",
       "      <td>-89.421544</td>\n",
       "      <td>2018-02-27</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>S46958065</td>\n",
       "      <td>Mallard</td>\n",
       "      <td>County V Ponds (Dane Co.)</td>\n",
       "      <td>43.247843</td>\n",
       "      <td>-89.429111</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>184</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index sampling_event_identifier     common name  \\\n",
       "0      3                 S46395227  Red-eyed Vireo   \n",
       "1      4                 S47723667     Pine Siskin   \n",
       "2      5                 S44649385         Mallard   \n",
       "3     15                 S43252514         Mallard   \n",
       "4     16                 S46958065         Mallard   \n",
       "\n",
       "                                            locality   latitude  longitude  \\\n",
       "0              Riverside Park (Urban Ecology Center)  43.067967 -87.892686   \n",
       "1                      Schlitz Audubon Nature Center  43.175688 -87.890421   \n",
       "2                                Manitowoc Lakefront  44.092794 -87.650170   \n",
       "3  UW Lakeshore Nature Preserve--Willow Creek Woo...  43.077869 -89.421544   \n",
       "4                          County V Ponds (Dane Co.)  43.247843 -89.429111   \n",
       "\n",
       "  observation_date  all_species_reported  year_week  year_day  year  \n",
       "0       2018-06-07                     1         23       158  2018  \n",
       "1       2018-08-08                     1         32       220  2018  \n",
       "2       2018-04-16                     1         16       106  2018  \n",
       "3       2018-02-27                     1          9        58  2018  \n",
       "4       2018-07-03                     1         27       184  2018  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfAll = pd.read_csv('./ebd_US-WY_201801_201912_relApr-2020/ebd_US-WY_201801_201912_relApr-2020.txt'\n",
    "#                 ,delimiter=\"\\t\")\n",
    "\n",
    "dfAll = pd.read_csv('../ebd_US-WI_201801_201912_relApr-2020/ebd_US-WI_201801_201912_relApr-2020.txt'\n",
    "                ,delimiter=\"\\t\", usecols=['CATEGORY', 'LOCALITY TYPE', 'ALL SPECIES REPORTED', 'APPROVED',\n",
    "                                         'SAMPLING EVENT IDENTIFIER', 'COMMON NAME', 'LOCALITY', \n",
    "                                          'LATITUDE', 'LONGITUDE',\n",
    "                                          'OBSERVATION DATE', 'ALL SPECIES REPORTED'])\n",
    "\n",
    "# dfAll = pd.read_csv('./ebd_US-WI_201001_201812_relApr-2020/ebd_US-WI_201001_201812_relApr-2020.txt'\n",
    "#                 ,delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I add sertain condition to satify completnes fo the data, public locations and only bird species (i.e. no hybirds). `dfReduce` will contian all the information I will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll = dfAll[(dfAll['CATEGORY'] == 'species') & (dfAll['LOCALITY TYPE'] == 'H')\n",
    "              & (dfAll['ALL SPECIES REPORTED'] == 1)  & (dfAll['APPROVED'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReduce = dfAll.filter(['SAMPLING EVENT IDENTIFIER', 'COMMON NAME', 'LOCALITY',\n",
    "              'LATITUDE', 'LONGITUDE', 'OBSERVATION DATE', 'ALL SPECIES REPORTED']) \n",
    "dfReduce['OBSERVATION DATE'] = pd.to_datetime(dfReduce['OBSERVATION DATE'])\n",
    "dfReduce['YEAR WEEK'] = dfReduce['OBSERVATION DATE'].dt.strftime('%W')\n",
    "dfReduce['YEAR DAY'] = dfReduce['OBSERVATION DATE'].dt.strftime('%j')\n",
    "dfReduce['YEAR'] = dfReduce['OBSERVATION DATE'].dt.strftime('%Y')\n",
    "dfReduce['YEAR WEEK'] = pd.to_numeric(dfReduce['YEAR WEEK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReduce.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dfReduce contains both my train set and my validation set.  In this case I will use the last year as my validation set (2019) and all the previous information as my train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfValidation = dfReduce[dfReduce['YEAR']==2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain = dfReduce[dfReduce['YEAR']!=2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfReduce\n",
    "del dfAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(dfTrain['LOCALITY'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering using BDSCAN\n",
    "\n",
    "BDSCAN is a density clustering that will tell where is popular for people to go birding (based on the desnity of hotsopts).  I will define a cluster as having atleast 3 point and with a maximum distance of 0.05degrees or about 5km.  With that I will optain where does each hotspot ('LOCALITY') belongs to. If '-1' they are not part of any cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcluster, labels, n_clusters_ = DBScaner.cluster_selection(dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfProb = DBScaner.cluster_center(dfcluster, dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now some good plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = gpd.read_file('/Users/casanova/DocumentsHere/Insight/Project/gz_2010_us_040_00_5m.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = 'Wyoming'\n",
    "state = 'Wisconsin'\n",
    "\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.viridis_r(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(7,8))\n",
    "base = country[country['NAME'].isin([state]) == True].plot(ax=ax, color='#3B3C6E', alpha = 0.3)\n",
    "for i, clust in enumerate(labels):\n",
    "    ax.scatter(np.array(dfcluster['LONGITUDE'])[i],np.array(dfcluster['LATITUDE'])[i], color = colors[clust])\n",
    "# ax.scatter(dfcluster['LONGITUDE'],dfcluster['LATITUDE'])\n",
    "ax.scatter(dfProb['LONGITUDE'],dfProb['LATITUDE'], marker = 'x', color = 'r', s=80)\n",
    "ax.set_ylabel(r'Latitude [$^o$]')\n",
    "ax.set_xlabel(r'Longitude [$^o$]')\n",
    "# save_fig('/Users/casanova/DocumentsHere/Insight/{}-static.png'.format(state))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(7,8))\n",
    "base = country[country['NAME'].isin([state]) == True].plot(ax=ax, color='#3B3C6E', alpha = 0.3)\n",
    "ax.scatter(dfcluster['LONGITUDE'],dfcluster['LATITUDE'])#, color = colors[clust])\n",
    "# ax.scatter(dfProb['LONGITUDE'],dfProb['LATITUDE'], marker = 'x', color = 'r', s=80)\n",
    "ax.set_ylabel(r'Latitude [$^o$]')\n",
    "ax.set_xlabel(r'Longitude [$^o$]')\n",
    "\n",
    "plt.show()\n",
    "# save_fig('/Users/casanova/DocumentsHere/Insight/WI.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the bird probability.\n",
    "\n",
    "`dfbdscan` have the information of where each of the hotspots lay, in terms of their cluster.  Now in order to constuct a path is important to mask the probabilites of the of seeing a particular bird with T or F on a weekly basis.  This is critical in order to construc the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfProb = dfTrain.merge(dfbdscan.filter(['LOCALITY','BD CLUSTER']),\n",
    "                            left_on='LOCALITY', right_on='LOCALITY', how = 'left').filter(['COMMON NAME','ALL SPECIES REPORTED','YEAR WEEK', 'BD CLUSTER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfProb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTime = 54\n",
    "nLoc = n_clusters_\n",
    "setMat = np.empty((nTime,nLoc), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for week in range(0,nTime):\n",
    "    dfProbA = dfProb[dfProb['YEAR WEEK']== week]\n",
    "    dfProb1 = dfProbA.groupby(['COMMON NAME','BD CLUSTER']).sum().filter(['ALL SPECIES REPORTED']).reset_index()\n",
    "    dfProb1.rename(columns = {'ALL SPECIES REPORTED':'POS OBS'}, inplace=True)\n",
    "    dfProb2 = dfProbA.groupby(['BD CLUSTER']).sum().filter(['ALL SPECIES REPORTED']).reset_index()\n",
    "    dfProb2.rename(columns = {'ALL SPECIES REPORTED':'TOT OBS'}, inplace=True)\n",
    "    dfProb3 = dfProb1.merge(dfProb2, left_on='BD CLUSTER', right_on='BD CLUSTER', how = 'left')\n",
    "    dfProb3['POS PROB'] = dfProb3['POS OBS']/dfProb3['TOT OBS']\n",
    "    for loc in range(0,nLoc):\n",
    "        dfWeek = dfProb3[dfProb3['BD CLUSTER'] == loc]\n",
    "        dfWeek['TF aa'] = list(map(lambda x: 0 if x < 0.02 else 1, dfWeek['POS PROB']))\n",
    "        setMat[week,loc] = set(dfWeek[dfWeek['TF aa'] == 1]['COMMON NAME'].values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(setMat, open(\"./2dSetLocations.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToMakeUniverse = list(setMat.flatten())\n",
    "Universe = set(e for s in ToMakeUniverse for e in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(Universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we go!!!!!\n",
    "\n",
    "First user inputs some coordinates.\n",
    "Then the coordinates get translated to a cluster.\n",
    "That give us the first set (first week)\n",
    "Then we obtain the rest of the sets. The key here is to back track a set to an actual 'x,t' entry so we can have a route.\n",
    "Display in some way that list of locations!  (Probabily using the centroid maps or coordinates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userInputLat,userInputLon = 44, -110\n",
    "userInputLat,userInputLon = 43.069511, -89.396723\n",
    "\n",
    "userInput = [userInputLat,userInputLon]\n",
    "print(userInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the first week I most see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setMatLoaded = pickle.load(open(\"./2dSetLocations.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hole list of bird that we are planing to see are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ToMakeUniverse = list(setMatLoaded.flatten())\n",
    "Universe = set(e for s in ToMakeUniverse for e in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('With a total of', len(list(Universe)), 'birds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setList, locList = SetCover.set_cover_greedy(Universe, ToMakeUniverse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locList = np.sort(locList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTime, nLoc = setMatLoaded.shape\n",
    "locMat = np.linspace(1,nTime*nLoc,nTime*nLoc).reshape(nTime,nLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outList = []\n",
    "for element in locList:\n",
    "    a,b = np.where(locMat == element)\n",
    "    outList.append('On week {}, you need to be at location {}'.format(a[0],b[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plaing with google distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distMat = np.empty((nTime,n_clusters_))\n",
    "countBreak = divmod(n_clusters_,100)\n",
    "\n",
    "for i in range(0,countBreak[0]):\n",
    "    distanceMatGmaps = gmaps.distance_matrix(origins = (userInput[0],userInput[1]), \n",
    "                                         destinations=list(coorHotspot[100*i:100*(i+1)]),\n",
    "                                         mode = 'driving', units = 'metric')\n",
    "    for j in range(100*i,100*(i+1)):\n",
    "        jj = j - 100*i\n",
    "        try:\n",
    "            distMat[:,j] = distanceMatGmaps['rows'][0]['elements'][jj]['duration']['value']/3600\n",
    "        except KeyError:\n",
    "            distMat[:,j] = 100\n",
    "        \n",
    "distanceMatGmaps = gmaps.distance_matrix(origins = (userInput[0],userInput[1]), \n",
    "                                         destinations=list(coorHotspot[countBreak[0]*100:]),\n",
    "                                         mode = 'driving', units = 'metric')\n",
    "\n",
    "for j in range(countBreak[0]*100,countBreak[0]*100+countBreak[1]):\n",
    "    jj = j - countBreak[0]*100\n",
    "    try:\n",
    "        distMat[:,j] = distanceMatGmaps['rows'][0]['elements'][jj]['duration']['value']/3600\n",
    "    except KeyError:\n",
    "        distMat[:,j] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = SetCover.set_cover_weighted_greedy(Universe, ToMakeUniverse,list(distMat.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locListb = np.sort(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locListb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outList = []\n",
    "for element in locListb:\n",
    "    a,b = np.where(locMat == element)\n",
    "    outList.append('On week {}, you need to be at location {}'.format(a[0],b[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
